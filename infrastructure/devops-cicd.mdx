# DevOps CI/CD

AWO Platform implements a comprehensive CI/CD pipeline optimized for African fintech operations, emphasizing security, compliance, and reliable deployment across multiple regions with varying infrastructure conditions.

## CI/CD Strategy Overview

<Info>
AWO's CI/CD approach prioritizes **security-first deployments** with automated compliance checking, comprehensive testing, and intelligent rollback mechanisms designed for the unique challenges of African infrastructure and regulatory environments.
</Info>

### CI/CD Philosophy and Principles

**1. Security-First Pipeline**
- Automated security scanning at every stage
- Compliance validation before deployment
- Secret management with regional encryption
- Immutable deployment artifacts with full traceability

**2. African Infrastructure Resilience**
- Multi-region deployment strategies for SADC coverage
- Intelligent rollback with network condition awareness
- Deployment scheduling for optimal African connectivity windows
- Bandwidth-optimized deployment packages and updates

**3. Compliance Automation**
- Automated regulatory compliance checking (POPIA, GDPR, local regulations)
- Financial audit trail generation for all deployments
- Automated penetration testing and vulnerability assessments
- Real-time compliance monitoring and alerting

**4. Developer Experience Excellence**
- Fast feedback loops with parallel execution
- Branch-based deployments with automatic cleanup
- Interactive deployment dashboards and notifications
- Comprehensive test reporting and debugging tools

## Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                CI/CD PIPELINE OVERVIEW                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Source Control                         â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚  Git    â”‚ â”‚ Feature â”‚ â”‚Release  â”‚ â”‚   Hotfix    â”‚â”‚ â”‚
â”‚  â”‚  â”‚ Flow    â”‚ â”‚ Branch  â”‚ â”‚ Branch  â”‚ â”‚   Branch    â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                              â”‚
â”‚                         â”‚ Webhook Triggers              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚             Continuous Integration                  â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚              Build Stage                        â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Code    â”‚ â”‚ Lint &  â”‚ â”‚ Type    â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Checkoutâ”‚ â”‚ Format  â”‚ â”‚ Check   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Install â”‚ â”‚  Build  â”‚ â”‚ Bundle  â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Deps   â”‚ â”‚ Assets  â”‚ â”‚Optimize â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚               Test Stage                        â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Unit   â”‚ â”‚Integr.  â”‚ â”‚  E2E    â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Tests   â”‚ â”‚ Tests   â”‚ â”‚ Tests   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Security â”‚ â”‚Complianceâ”‚ â”‚Performanceâ”‚          â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Scan    â”‚ â”‚ Check   â”‚ â”‚ Test    â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚              Quality Stage                      â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Code    â”‚ â”‚SAST     â”‚ â”‚ Vulner. â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Coverage â”‚ â”‚Analysis â”‚ â”‚ Scan    â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚License  â”‚ â”‚ Audit   â”‚ â”‚Report   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Check   â”‚ â”‚ Trail   â”‚ â”‚Generate â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                              â”‚
â”‚                         â”‚ Artifacts & Approval          â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            Continuous Deployment                    â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚              Staging Deploy                     â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Deploy  â”‚ â”‚Database â”‚ â”‚Service  â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Code    â”‚ â”‚Migrationâ”‚ â”‚ Health  â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Smoke    â”‚ â”‚Integrationâ”‚ â”‚ User   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Tests    â”‚ â”‚ Tests   â”‚ â”‚Acceptanceâ”‚          â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚            Production Deploy                    â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Regional â”‚ â”‚Blue/Greenâ”‚ â”‚Health   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Rollout  â”‚ â”‚ Deploy  â”‚ â”‚ Monitor â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Complianceâ”‚ â”‚Financialâ”‚ â”‚ Alert   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Validate â”‚ â”‚ Verify  â”‚ â”‚ Setup   â”‚           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Backend CI/CD Pipeline

### GitHub Actions Workflow for Express.js

**Main CI/CD Workflow**
```yaml
# .github/workflows/backend-cicd.yml
name: Backend CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    paths: ['backend/**', '.github/workflows/backend-cicd.yml']
  pull_request:
    branches: [main, develop]
    paths: ['backend/**']
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: awo-platform/backend

jobs:
  # Stage 1: Security and Quality Checks
  security-scan:
    name: Security & Compliance Scan
    runs-on: ubuntu-latest
    outputs:
      security-passed: ${{ steps.security-check.outputs.passed }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # Fetch full history for comprehensive security scanning
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json
      
      - name: Install dependencies
        working-directory: backend
        run: |
          npm ci --audit-level=moderate
          npm audit --audit-level=moderate
      
      - name: Run security audit
        working-directory: backend
        run: |
          # Check for known vulnerabilities
          npm audit --audit-level=moderate --production
          
          # Generate security report
          npm audit --json > security-audit.json
      
      - name: SAST (Static Application Security Testing)
        uses: github/super-linter@v5
        env:
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VALIDATE_TYPESCRIPT_ES: true
          VALIDATE_DOCKERFILE_HADOLINT: true
          VALIDATE_YAML: true
      
      - name: CodeQL Security Analysis
        uses: github/codeql-action/init@v3
        with:
          languages: javascript,typescript
          
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
      
      - name: Snyk vulnerability scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --file=backend/package.json --severity-threshold=high
      
      - name: Financial compliance check
        id: security-check
        working-directory: backend
        run: |
          # Custom AWO compliance checker
          node scripts/compliance-check.js
          echo "passed=true" >> $GITHUB_OUTPUT
  
  # Stage 2: Build and Test
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    needs: security-scan
    if: needs.security-scan.outputs.security-passed == 'true'
    
    strategy:
      matrix:
        test-type: [unit, integration, e2e]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: awo_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json
      
      - name: Install dependencies
        working-directory: backend
        run: npm ci
      
      - name: TypeScript compilation check
        working-directory: backend
        run: npm run type-check
      
      - name: Lint code
        working-directory: backend
        run: npm run lint
      
      - name: Run tests
        working-directory: backend
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://postgres:test_password@localhost:5432/awo_test
          REDIS_URL: redis://localhost:6379
        run: |
          case "${{ matrix.test-type }}" in
            unit)
              npm run test:unit -- --coverage --coverageReporters=text-lcov > coverage.lcov
              ;;
            integration)
              npm run test:integration
              ;;
            e2e)
              npm run test:e2e
              ;;
          esac
      
      - name: Upload coverage to Codecov
        if: matrix.test-type == 'unit'
        uses: codecov/codecov-action@v3
        with:
          file: backend/coverage.lcov
          flags: backend,unit
      
      - name: Performance testing
        if: matrix.test-type == 'e2e'
        working-directory: backend
        run: |
          # Run performance tests to ensure African network optimization
          npm run test:performance
          
          # Generate performance report
          node scripts/performance-report.js
      
      - name: Financial calculation validation
        if: matrix.test-type == 'integration'
        working-directory: backend
        run: |
          # Validate DIVA scoring accuracy
          npm run test:diva-accuracy
          
          # Test payment processing with test cards
          npm run test:payment-flows
      
      - name: Build application
        working-directory: backend
        run: |
          npm run build
          
          # Verify build artifacts
          ls -la dist/
          node dist/healthcheck.js

  # Stage 3: Container Build and Push
  container-build:
    name: Build and Push Container
    runs-on: ubuntu-latest
    needs: [security-scan, build-and-test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
      
      - name: Build and push container
        uses: docker/build-push-action@v5
        with:
          context: backend
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            NODE_VERSION=${{ env.NODE_VERSION }}
            BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
            GIT_COMMIT=${{ github.sha }}
      
      - name: Run container security scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  # Stage 4: Staging Deployment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [security-scan, build-and-test, container-build]
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup deployment tools
        run: |
          # Install deployment dependencies
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
      
      - name: Deploy to Railway Staging
        env:
          RAILWAY_TOKEN: ${{ secrets.RAILWAY_STAGING_TOKEN }}
        run: |
          # Deploy to Railway staging environment
          npm install -g @railway/cli
          railway login --token $RAILWAY_TOKEN
          railway environment staging
          railway up --service backend
      
      - name: Run database migrations
        env:
          DATABASE_URL: ${{ secrets.STAGING_DATABASE_URL }}
        run: |
          cd backend
          npm run migrate:up
      
      - name: Staging smoke tests
        env:
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
        run: |
          # Wait for deployment to be ready
          sleep 30
          
          # Run smoke tests against staging
          cd backend
          npm run test:smoke -- --baseUrl=$STAGING_API_URL
      
      - name: Financial system validation
        env:
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
        run: |
          # Validate DIVA scoring in staging
          cd backend
          npm run validate:diva-staging
          
          # Test payment flows with test accounts
          npm run validate:payments-staging

  # Stage 5: Production Deployment
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Pre-deployment checks
        run: |
          # Verify staging tests passed
          echo "Running pre-deployment validation..."
          
          # Check service health in staging
          curl -f ${{ secrets.STAGING_API_URL }}/health || exit 1
          
          # Validate compliance requirements
          node scripts/pre-deploy-compliance-check.js
      
      - name: Blue-Green deployment to Production
        env:
          RAILWAY_TOKEN: ${{ secrets.RAILWAY_PRODUCTION_TOKEN }}
        run: |
          # Deploy to Railway production with blue-green strategy
          railway login --token $RAILWAY_TOKEN
          railway environment production
          
          # Deploy to blue environment first
          railway up --service backend-blue
          
          # Validate blue environment
          sleep 60
          curl -f ${{ secrets.PRODUCTION_BLUE_URL }}/health
          
          # Switch traffic to blue environment
          railway variables set ACTIVE_ENVIRONMENT=blue
          
          # Monitor for 5 minutes before cleaning up green
          sleep 300
      
      - name: Production database migration
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}
        run: |
          cd backend
          npm run migrate:up:production
      
      - name: Post-deployment verification
        env:
          PRODUCTION_API_URL: ${{ secrets.PRODUCTION_API_URL }}
        run: |
          # Comprehensive production validation
          cd backend
          npm run test:production-verification
          
          # Validate all critical endpoints
          npm run test:critical-paths -- --baseUrl=$PRODUCTION_API_URL
          
          # Monitor error rates for 10 minutes
          node scripts/post-deploy-monitor.js
      
      - name: Notify deployment success
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: "âœ… AWO Backend successfully deployed to production"
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: success()
      
      - name: Notify deployment failure
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: "âŒ AWO Backend deployment to production failed"
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: failure()
```

## Mobile CI/CD Pipeline (React Native)

### EAS Build and Deployment Workflow

**React Native CI/CD with Expo EAS**
```yaml
# .github/workflows/mobile-cicd.yml
name: Mobile CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    paths: ['mobile/**', '.github/workflows/mobile-cicd.yml']
  pull_request:
    branches: [main, develop]
    paths: ['mobile/**']

env:
  NODE_VERSION: '18'
  EXPO_CLI_VERSION: 'latest'

jobs:
  # Stage 1: Mobile App Testing
  mobile-test:
    name: Mobile Tests and Quality
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: mobile/package-lock.json
      
      - name: Setup Expo CLI
        run: npm install -g @expo/cli@${{ env.EXPO_CLI_VERSION }}
      
      - name: Install dependencies
        working-directory: mobile
        run: npm ci
      
      - name: TypeScript check
        working-directory: mobile
        run: npx tsc --noEmit
      
      - name: Lint and format check
        working-directory: mobile
        run: |
          npm run lint
          npm run format:check
      
      - name: Run unit tests
        working-directory: mobile
        run: npm run test -- --coverage --watchAll=false
      
      - name: Run React Native tests
        working-directory: mobile
        run: |
          # Test bundle for Android
          npx expo export:embed --platform android --dev false
          
          # Test bundle for iOS  
          npx expo export:embed --platform ios --dev false
      
      - name: Security scan for mobile
        working-directory: mobile
        run: |
          # Check for security vulnerabilities in mobile dependencies
          npm audit --audit-level=moderate
          
          # Check for hardcoded secrets
          grep -r "sk_live\|pk_live\|api_key" src/ && exit 1 || true
      
      - name: Upload test coverage
        uses: codecov/codecov-action@v3
        with:
          file: mobile/coverage/lcov.info
          flags: mobile,unit

  # Stage 2: EAS Build for Testing
  eas-build-preview:
    name: EAS Build (Preview)
    runs-on: ubuntu-latest
    needs: mobile-test
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: mobile/package-lock.json
      
      - name: Setup Expo and EAS
        run: |
          npm install -g @expo/cli@${{ env.EXPO_CLI_VERSION }}
          npm install -g eas-cli@latest
      
      - name: Install dependencies
        working-directory: mobile
        run: npm ci
      
      - name: EAS Login
        working-directory: mobile
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}
        run: eas login --non-interactive
      
      - name: Build preview for Android
        working-directory: mobile
        run: |
          # Build APK for testing
          eas build --platform android --profile preview --non-interactive
      
      - name: Build preview for iOS
        working-directory: mobile
        run: |
          # Build for iOS simulator testing
          eas build --platform ios --profile preview --non-interactive
      
      - name: Comment PR with build links
        uses: actions/github-script@v7
        with:
          script: |
            const { data: builds } = await github.rest.actions.listWorkflowRuns({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: context.workflow
            });
            
            const comment = `
            ðŸ“± **Mobile App Builds Ready for Testing**
            
            - Android APK: Available in EAS dashboard
            - iOS Simulator: Available in EAS dashboard
            
            Download links will be available in the EAS dashboard within 10-15 minutes.
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Stage 3: Production Mobile Builds
  eas-build-production:
    name: EAS Build (Production)
    runs-on: ubuntu-latest
    needs: mobile-test
    if: github.ref == 'refs/heads/main'
    
    strategy:
      matrix:
        platform: [android, ios]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js and dependencies
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: mobile/package-lock.json
      
      - name: Setup Expo and EAS
        run: |
          npm install -g @expo/cli@${{ env.EXPO_CLI_VERSION }}
          npm install -g eas-cli@latest
      
      - name: Install dependencies
        working-directory: mobile
        run: npm ci
      
      - name: EAS Login
        working-directory: mobile
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}
        run: eas login --non-interactive
      
      - name: Build for app stores
        working-directory: mobile
        env:
          APPLE_ID: ${{ secrets.APPLE_ID }}
          APPLE_APP_SPECIFIC_PASSWORD: ${{ secrets.APPLE_APP_SPECIFIC_PASSWORD }}
        run: |
          # Update app version
          node scripts/update-version.js
          
          # Build for production
          if [ "${{ matrix.platform }}" = "android" ]; then
            eas build --platform android --profile production --non-interactive
          else
            eas build --platform ios --profile production --non-interactive
          fi
      
      - name: Submit to app stores
        working-directory: mobile
        if: github.ref == 'refs/heads/main'
        run: |
          if [ "${{ matrix.platform }}" = "android" ]; then
            # Submit to Google Play Store (internal testing first)
            eas submit --platform android --profile production
          else
            # Submit to App Store Connect (TestFlight first)
            eas submit --platform ios --profile production
          fi
      
      - name: Create GitHub release
        if: matrix.platform == 'android' && github.ref == 'refs/heads/main'
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: mobile-v${{ github.run_number }}
          release_name: AWO Mobile v${{ github.run_number }}
          body: |
            ðŸš€ AWO Mobile App Release
            
            **What's New:**
            - Latest features and improvements
            - Security updates and bug fixes
            - Performance optimizations for African networks
            
            **Download:**
            - Android: Available on Google Play Store
            - iOS: Available on App Store
          draft: false
          prerelease: false

  # Stage 4: E2E Testing on Real Devices
  e2e-testing:
    name: E2E Testing
    runs-on: ubuntu-latest
    needs: eas-build-preview
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: mobile/package-lock.json
      
      - name: Install dependencies
        working-directory: mobile
        run: npm ci
      
      - name: Install Maestro for E2E testing
        run: |
          curl -Ls "https://get.maestro.mobile.dev" | bash
          export PATH="$PATH":"$HOME/.maestro/bin"
      
      - name: Run E2E tests
        working-directory: mobile
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}
          TEST_USER_EMAIL: ${{ secrets.TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.TEST_USER_PASSWORD }}
        run: |
          # Run critical user journey tests
          maestro test e2e/user-onboarding.yaml
          maestro test e2e/diva-calculation.yaml
          maestro test e2e/chama-creation.yaml
          maestro test e2e/payment-flow.yaml
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: mobile/e2e/reports/
```

## Infrastructure as Code (IaC)

### Terraform Configuration for Multi-Region Deployment

**Main Infrastructure Configuration**
```hcl
# infrastructure/main.tf
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    cloudflare = {
      source  = "cloudflare/cloudflare"
      version = "~> 4.0"
    }
  }
  
  backend "s3" {
    bucket = "awo-terraform-state"
    key    = "production/terraform.tfstate"
    region = "af-south-1"
    
    # State locking
    dynamodb_table = "awo-terraform-locks"
    encrypt       = true
  }
}

# Configure AWS providers for multi-region
provider "aws" {
  alias  = "af_south"
  region = "af-south-1" # Cape Town - Primary region
  
  default_tags {
    tags = {
      Project     = "AWO Platform"
      Environment = var.environment
      ManagedBy   = "Terraform"
      Region      = "Africa-South"
    }
  }
}

provider "aws" {
  alias  = "eu_west"
  region = "eu-west-1" # Ireland - For GDPR compliance
  
  default_tags {
    tags = {
      Project     = "AWO Platform"
      Environment = var.environment
      ManagedBy   = "Terraform"
      Region      = "Europe-West"
    }
  }
}

# Cloudflare for global CDN and security
provider "cloudflare" {
  api_token = var.cloudflare_api_token
}

# Local variables
locals {
  app_name = "awo-platform"
  
  regions = {
    primary = {
      name        = "af-south-1"
      az_count    = 2
      provider    = "af_south"
    }
    secondary = {
      name        = "eu-west-1"
      az_count    = 2
      provider    = "eu_west"
    }
  }
  
  common_tags = {
    Project     = local.app_name
    Environment = var.environment
    CostCenter  = "Engineering"
    Owner       = "DevOps"
  }
}

# Data sources
data "aws_availability_zones" "primary" {
  provider = aws.af_south
  state    = "available"
}

data "aws_availability_zones" "secondary" {
  provider = aws.eu_west
  state    = "available"
}

# VPC and Networking for Primary Region (Africa South)
module "vpc_primary" {
  source = "./modules/vpc"
  
  providers = {
    aws = aws.af_south
  }
  
  name = "${local.app_name}-${var.environment}-primary"
  cidr = "10.0.0.0/16"
  
  azs             = slice(data.aws_availability_zones.primary.names, 0, 2)
  public_subnets  = ["10.0.1.0/24", "10.0.2.0/24"]
  private_subnets = ["10.0.11.0/24", "10.0.12.0/24"]
  
  enable_nat_gateway = true
  enable_vpn_gateway = false
  
  # Enable flow logs for security monitoring
  enable_flow_log               = true
  flow_log_destination_type     = "cloud-watch-logs"
  create_flow_log_cloudwatch_iam_role = true
  
  tags = local.common_tags
}

# Application Load Balancer for Primary Region
module "alb_primary" {
  source = "./modules/alb"
  
  providers = {
    aws = aws.af_south
  }
  
  name = "${local.app_name}-${var.environment}-primary-alb"
  
  vpc_id          = module.vpc_primary.vpc_id
  public_subnets  = module.vpc_primary.public_subnets
  
  # Security group allowing HTTPS traffic
  security_group_rules = {
    ingress_https = {
      type        = "ingress"
      from_port   = 443
      to_port     = 443
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
    ingress_http = {
      type        = "ingress"
      from_port   = 80
      to_port     = 80
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
    egress_all = {
      type        = "egress"
      from_port   = 0
      to_port     = 0
      protocol    = "-1"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }
  
  # SSL certificate
  certificate_arn = aws_acm_certificate.primary.arn
  
  tags = local.common_tags
}

# ECS Cluster for containerized applications
module "ecs_primary" {
  source = "./modules/ecs"
  
  providers = {
    aws = aws.af_south
  }
  
  cluster_name = "${local.app_name}-${var.environment}-primary"
  
  # Capacity providers for cost optimization
  capacity_providers = ["FARGATE", "FARGATE_SPOT"]
  
  default_capacity_provider_strategy = [
    {
      capacity_provider = "FARGATE_SPOT"
      weight           = 70
      base            = 0
    },
    {
      capacity_provider = "FARGATE"
      weight           = 30
      base            = 1
    }
  ]
  
  tags = local.common_tags
}

# ECS Service for Backend API
resource "aws_ecs_service" "backend_api" {
  provider = aws.af_south
  
  name            = "${local.app_name}-backend-api"
  cluster         = module.ecs_primary.cluster_id
  task_definition = aws_ecs_task_definition.backend_api.arn
  desired_count   = var.environment == "production" ? 3 : 1
  
  # Use both Fargate and Fargate Spot for cost optimization
  capacity_provider_strategy {
    capacity_provider = "FARGATE_SPOT"
    weight           = 70
    base            = 0
  }
  
  capacity_provider_strategy {
    capacity_provider = "FARGATE"
    weight           = 30
    base            = 1
  }
  
  network_configuration {
    subnets          = module.vpc_primary.private_subnets
    security_groups  = [aws_security_group.backend_api.id]
    assign_public_ip = false
  }
  
  load_balancer {
    target_group_arn = module.alb_primary.target_group_arns["backend-api"]
    container_name   = "backend-api"
    container_port   = 3000
  }
  
  # Health check grace period for African network conditions
  health_check_grace_period_seconds = 120
  
  # Rolling update configuration
  deployment_configuration {
    maximum_percent         = 200
    minimum_healthy_percent = 50
  }
  
  tags = local.common_tags
}

# CloudWatch Log Groups for centralized logging
resource "aws_cloudwatch_log_group" "backend_api" {
  provider = aws.af_south
  
  name              = "/aws/ecs/${local.app_name}-backend-api"
  retention_in_days = var.environment == "production" ? 90 : 30
  
  tags = local.common_tags
}

# CloudWatch Alarms for monitoring
resource "aws_cloudwatch_metric_alarm" "backend_api_cpu" {
  provider = aws.af_south
  
  alarm_name          = "${local.app_name}-backend-api-high-cpu"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/ECS"
  period              = "300"
  statistic           = "Average"
  threshold           = "80"
  alarm_description   = "This metric monitors ECS CPU utilization"
  
  dimensions = {
    ServiceName = aws_ecs_service.backend_api.name
    ClusterName = module.ecs_primary.cluster_name
  }
  
  alarm_actions = [aws_sns_topic.alerts.arn]
  
  tags = local.common_tags
}

# Auto Scaling for ECS Service
resource "aws_appautoscaling_target" "backend_api" {
  provider = aws.af_south
  
  max_capacity       = var.environment == "production" ? 10 : 3
  min_capacity       = var.environment == "production" ? 2 : 1
  resource_id        = "service/${module.ecs_primary.cluster_name}/${aws_ecs_service.backend_api.name}"
  scalable_dimension = "ecs:service:DesiredCount"
  service_namespace  = "ecs"
}

resource "aws_appautoscaling_policy" "backend_api_scale_up" {
  provider = aws.af_south
  
  name               = "${local.app_name}-backend-api-scale-up"
  policy_type        = "TargetTrackingScaling"
  resource_id        = aws_appautoscaling_target.backend_api.resource_id
  scalable_dimension = aws_appautoscaling_target.backend_api.scalable_dimension
  service_namespace  = aws_appautoscaling_target.backend_api.service_namespace
  
  target_tracking_scaling_policy_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ECSServiceAverageCPUUtilization"
    }
    target_value = 70.0
    # Scale in protection for financial services
    scale_in_cooldown  = 600  # 10 minutes
    scale_out_cooldown = 300  # 5 minutes
  }
}
```

**Database Infrastructure**
```hcl
# infrastructure/database.tf

# Neon PostgreSQL is managed externally, but we configure related resources

# RDS Parameter Group for compatibility testing
resource "aws_db_parameter_group" "postgresql" {
  provider = aws.af_south
  
  family = "postgres15"
  name   = "${local.app_name}-${var.environment}-postgres15"
  
  parameter {
    name  = "log_statement"
    value = "all"
  }
  
  parameter {
    name  = "log_min_duration_statement"
    value = "1000" # Log queries taking longer than 1 second
  }
  
  tags = local.common_tags
}

# ElastiCache Redis for session storage and caching
resource "aws_elasticache_subnet_group" "redis" {
  provider = aws.af_south
  
  name       = "${local.app_name}-${var.environment}-redis"
  subnet_ids = module.vpc_primary.private_subnets
  
  tags = local.common_tags
}

resource "aws_elasticache_replication_group" "redis" {
  provider = aws.af_south
  
  replication_group_id         = "${local.app_name}-${var.environment}-redis"
  description                  = "Redis cluster for AWO Platform"
  
  node_type                   = var.environment == "production" ? "cache.r7g.large" : "cache.t4g.micro"
  port                        = 6379
  parameter_group_name        = "default.redis7"
  
  num_cache_clusters         = var.environment == "production" ? 2 : 1
  
  engine_version             = "7.0"
  subnet_group_name          = aws_elasticache_subnet_group.redis.name
  security_group_ids         = [aws_security_group.redis.id]
  
  # Security and backup configuration
  at_rest_encryption_enabled = true
  transit_encryption_enabled = true
  auth_token                = var.redis_auth_token
  
  # Automated backups
  snapshot_retention_limit = var.environment == "production" ? 7 : 1
  snapshot_window         = "03:00-05:00"  # UTC - early morning in Africa
  
  # Maintenance window
  maintenance_window = "sun:05:00-sun:06:00"  # UTC
  
  # Auto failover for production
  automatic_failover_enabled = var.environment == "production"
  multi_az_enabled          = var.environment == "production"
  
  tags = local.common_tags
}

# Security group for Redis
resource "aws_security_group" "redis" {
  provider = aws.af_south
  
  name_prefix = "${local.app_name}-${var.environment}-redis-"
  vpc_id      = module.vpc_primary.vpc_id
  
  ingress {
    from_port       = 6379
    to_port         = 6379
    protocol        = "tcp"
    security_groups = [aws_security_group.backend_api.id]
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = merge(local.common_tags, {
    Name = "${local.app_name}-${var.environment}-redis"
  })
}
```

## Deployment Automation Scripts

### Regional Deployment Script

**Multi-Region Deployment Orchestration**
```bash
#!/bin/bash
# scripts/deploy-multi-region.sh

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
ENVIRONMENT="${1:-staging}"
REGIONS=("af-south-1" "eu-west-1")
HEALTH_CHECK_TIMEOUT=300 # 5 minutes

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}"
    exit 1
}

# Validate environment
validate_environment() {
    if [[ ! "$ENVIRONMENT" =~ ^(staging|production)$ ]]; then
        error "Invalid environment: $ENVIRONMENT. Must be 'staging' or 'production'"
    fi
    
    log "Validating environment: $ENVIRONMENT"
    
    # Check required tools
    command -v terraform >/dev/null 2>&1 || error "terraform is required but not installed"
    command -v aws >/dev/null 2>&1 || error "aws CLI is required but not installed"
    command -v docker >/dev/null 2>&1 || error "docker is required but not installed"
    
    # Check AWS credentials
    aws sts get-caller-identity >/dev/null || error "AWS credentials not configured"
    
    log "Environment validation completed"
}

# Pre-deployment checks
pre_deployment_checks() {
    log "Running pre-deployment checks..."
    
    # Check if staging is healthy before production deployment
    if [[ "$ENVIRONMENT" == "production" ]]; then
        log "Checking staging environment health..."
        
        local staging_health
        staging_health=$(curl -sf "https://api-staging.awo-platform.com/health" | jq -r '.status')
        
        if [[ "$staging_health" != "healthy" ]]; then
            error "Staging environment is not healthy. Cannot proceed with production deployment."
        fi
        
        log "Staging environment is healthy"
    fi
    
    # Verify database migration scripts
    log "Validating database migrations..."
    cd "$PROJECT_ROOT/backend"
    npm run migrate:validate
    
    # Run compliance checks
    log "Running compliance validation..."
    node scripts/compliance-check.js
    
    log "Pre-deployment checks completed"
}

# Deploy infrastructure
deploy_infrastructure() {
    local region=$1
    log "Deploying infrastructure to region: $region"
    
    cd "$PROJECT_ROOT/infrastructure"
    
    # Initialize Terraform
    terraform init \
        -backend-config="key=$ENVIRONMENT/$region/terraform.tfstate"
    
    # Plan infrastructure changes
    terraform plan \
        -var="environment=$ENVIRONMENT" \
        -var="region=$region" \
        -out="$region.tfplan"
    
    # Apply infrastructure changes
    terraform apply "$region.tfplan"
    
    log "Infrastructure deployment completed for region: $region"
}

# Deploy application
deploy_application() {
    local region=$1
    log "Deploying application to region: $region"
    
    # Set AWS region
    export AWS_DEFAULT_REGION=$region
    
    # Update ECS service with new task definition
    local cluster_name="awo-platform-$ENVIRONMENT-$region"
    local service_name="awo-platform-backend-api"
    
    # Get current task definition
    local task_def
    task_def=$(aws ecs describe-task-definition \
        --task-definition "$service_name" \
        --query 'taskDefinition' \
        --output json)
    
    # Update image tag
    local new_image="ghcr.io/awo-platform/backend:$GITHUB_SHA"
    local updated_task_def
    updated_task_def=$(echo "$task_def" | jq \
        --arg IMAGE "$new_image" \
        '.containerDefinitions[0].image = $IMAGE | del(.taskDefinitionArn) | del(.revision) | del(.status) | del(.requiresAttributes) | del(.placementConstraints) | del(.compatibilities) | del(.registeredAt) | del(.registeredBy)')
    
    # Register new task definition
    local new_task_def_arn
    new_task_def_arn=$(echo "$updated_task_def" | aws ecs register-task-definition \
        --cli-input-json file:///dev/stdin \
        --query 'taskDefinition.taskDefinitionArn' \
        --output text)
    
    log "Registered new task definition: $new_task_def_arn"
    
    # Update ECS service
    aws ecs update-service \
        --cluster "$cluster_name" \
        --service "$service_name" \
        --task-definition "$new_task_def_arn" \
        --force-new-deployment
    
    log "Application deployment initiated for region: $region"
}

# Health check function
health_check() {
    local region=$1
    local endpoint
    
    if [[ "$region" == "af-south-1" ]]; then
        endpoint="https://api.awo-platform.com/health"
    else
        endpoint="https://api-eu.awo-platform.com/health"
    fi
    
    if [[ "$ENVIRONMENT" == "staging" ]]; then
        endpoint="${endpoint/api/api-staging}"
    fi
    
    log "Performing health check for region $region: $endpoint"
    
    local start_time
    start_time=$(date +%s)
    
    while true; do
        local current_time
        current_time=$(date +%s)
        local elapsed=$((current_time - start_time))
        
        if [[ $elapsed -gt $HEALTH_CHECK_TIMEOUT ]]; then
            error "Health check timeout for region $region after ${HEALTH_CHECK_TIMEOUT}s"
        fi
        
        if curl -sf "$endpoint" >/dev/null; then
            log "Health check passed for region $region"
            break
        fi
        
        warn "Health check failed for region $region, retrying in 30s..."
        sleep 30
    done
}

# Database migration
run_database_migrations() {
    log "Running database migrations..."
    
    cd "$PROJECT_ROOT/backend"
    
    # Set database URL for environment
    if [[ "$ENVIRONMENT" == "production" ]]; then
        export DATABASE_URL="$PRODUCTION_DATABASE_URL"
    else
        export DATABASE_URL="$STAGING_DATABASE_URL"
    fi
    
    # Run migrations
    npm run migrate:up
    
    # Verify migrations
    npm run migrate:status
    
    log "Database migrations completed"
}

# Rollback function
rollback() {
    local region=$1
    error "Deployment failed for region $region. Initiating rollback..."
    
    # Rollback ECS service to previous task definition
    # Implementation depends on your rollback strategy
    
    exit 1
}

# Main deployment function
deploy() {
    log "Starting AWO Platform deployment to $ENVIRONMENT environment"
    
    validate_environment
    pre_deployment_checks
    
    # Run database migrations first (only once, not per region)
    run_database_migrations
    
    # Deploy to each region
    for region in "${REGIONS[@]}"; do
        log "Deploying to region: $region"
        
        # Deploy infrastructure
        deploy_infrastructure "$region" || rollback "$region"
        
        # Deploy application
        deploy_application "$region" || rollback "$region"
        
        # Wait for deployment to stabilize
        sleep 60
        
        # Perform health check
        health_check "$region" || rollback "$region"
        
        log "Deployment successful for region: $region"
    done
    
    log "Multi-region deployment completed successfully!"
    
    # Send notification
    if command -v slack >/dev/null 2>&1; then
        slack chat send \
            --channel "#deployments" \
            --text "âœ… AWO Platform successfully deployed to $ENVIRONMENT environment across all regions"
    fi
}

# Error handling
trap 'error "Deployment script failed at line $LINENO"' ERR

# Run deployment
deploy "$@"
```

---

*This DevOps CI/CD documentation provides comprehensive guidance for implementing secure, automated deployment pipelines for AWO Platform, specifically designed for African fintech operations with multi-region compliance and reliability requirements.*

*Last updated: June 2025*  
*Next review: March 2025*